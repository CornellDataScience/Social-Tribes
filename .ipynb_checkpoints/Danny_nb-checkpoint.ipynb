{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "from scipy.interpolate import UnivariateSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>399</th>\n",
       "      <th>400</th>\n",
       "      <th>401</th>\n",
       "      <th>402</th>\n",
       "      <th>403</th>\n",
       "      <th>404</th>\n",
       "      <th>405</th>\n",
       "      <th>406</th>\n",
       "      <th>407</th>\n",
       "      <th>408</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.154615</td>\n",
       "      <td>0.128242</td>\n",
       "      <td>0.117036</td>\n",
       "      <td>0.096753</td>\n",
       "      <td>0.106672</td>\n",
       "      <td>0.216381</td>\n",
       "      <td>0.105924</td>\n",
       "      <td>0.244316</td>\n",
       "      <td>0.242717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080793</td>\n",
       "      <td>0.195271</td>\n",
       "      <td>0.106780</td>\n",
       "      <td>0.287842</td>\n",
       "      <td>0.079860</td>\n",
       "      <td>0.139011</td>\n",
       "      <td>0.176458</td>\n",
       "      <td>0.036928</td>\n",
       "      <td>0.207757</td>\n",
       "      <td>0.293838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.154615</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.096306</td>\n",
       "      <td>0.063149</td>\n",
       "      <td>0.057980</td>\n",
       "      <td>0.082548</td>\n",
       "      <td>0.126921</td>\n",
       "      <td>0.082246</td>\n",
       "      <td>0.185646</td>\n",
       "      <td>0.115409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064670</td>\n",
       "      <td>0.131949</td>\n",
       "      <td>0.115271</td>\n",
       "      <td>0.177713</td>\n",
       "      <td>0.045531</td>\n",
       "      <td>0.082933</td>\n",
       "      <td>0.115422</td>\n",
       "      <td>0.021049</td>\n",
       "      <td>0.176515</td>\n",
       "      <td>0.116874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.128242</td>\n",
       "      <td>0.096306</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.096306</td>\n",
       "      <td>0.074620</td>\n",
       "      <td>0.114210</td>\n",
       "      <td>0.257796</td>\n",
       "      <td>0.084923</td>\n",
       "      <td>0.113493</td>\n",
       "      <td>0.225923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055419</td>\n",
       "      <td>0.110993</td>\n",
       "      <td>0.083623</td>\n",
       "      <td>0.178426</td>\n",
       "      <td>0.097085</td>\n",
       "      <td>0.126835</td>\n",
       "      <td>0.145613</td>\n",
       "      <td>0.051699</td>\n",
       "      <td>0.133769</td>\n",
       "      <td>0.155928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.117036</td>\n",
       "      <td>0.063149</td>\n",
       "      <td>0.096306</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.063622</td>\n",
       "      <td>0.090841</td>\n",
       "      <td>0.116372</td>\n",
       "      <td>0.086262</td>\n",
       "      <td>0.078547</td>\n",
       "      <td>0.085417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064317</td>\n",
       "      <td>0.117952</td>\n",
       "      <td>0.074103</td>\n",
       "      <td>0.098842</td>\n",
       "      <td>0.103589</td>\n",
       "      <td>0.090239</td>\n",
       "      <td>0.109755</td>\n",
       "      <td>0.036189</td>\n",
       "      <td>0.149799</td>\n",
       "      <td>0.063875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.096753</td>\n",
       "      <td>0.057980</td>\n",
       "      <td>0.074620</td>\n",
       "      <td>0.063622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.118357</td>\n",
       "      <td>0.127003</td>\n",
       "      <td>0.055388</td>\n",
       "      <td>0.085349</td>\n",
       "      <td>0.129044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054978</td>\n",
       "      <td>0.083128</td>\n",
       "      <td>0.060337</td>\n",
       "      <td>0.105096</td>\n",
       "      <td>0.068538</td>\n",
       "      <td>0.087177</td>\n",
       "      <td>0.117711</td>\n",
       "      <td>0.035451</td>\n",
       "      <td>0.092469</td>\n",
       "      <td>0.146810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 409 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  1.000000  0.154615  0.128242  0.117036  0.096753  0.106672  0.216381   \n",
       "1  0.154615  1.000000  0.096306  0.063149  0.057980  0.082548  0.126921   \n",
       "2  0.128242  0.096306  1.000000  0.096306  0.074620  0.114210  0.257796   \n",
       "3  0.117036  0.063149  0.096306  1.000000  0.063622  0.090841  0.116372   \n",
       "4  0.096753  0.057980  0.074620  0.063622  1.000000  0.118357  0.127003   \n",
       "\n",
       "        7         8         9      ...          399       400       401  \\\n",
       "0  0.105924  0.244316  0.242717    ...     0.080793  0.195271  0.106780   \n",
       "1  0.082246  0.185646  0.115409    ...     0.064670  0.131949  0.115271   \n",
       "2  0.084923  0.113493  0.225923    ...     0.055419  0.110993  0.083623   \n",
       "3  0.086262  0.078547  0.085417    ...     0.064317  0.117952  0.074103   \n",
       "4  0.055388  0.085349  0.129044    ...     0.054978  0.083128  0.060337   \n",
       "\n",
       "        402       403       404       405       406       407       408  \n",
       "0  0.287842  0.079860  0.139011  0.176458  0.036928  0.207757  0.293838  \n",
       "1  0.177713  0.045531  0.082933  0.115422  0.021049  0.176515  0.116874  \n",
       "2  0.178426  0.097085  0.126835  0.145613  0.051699  0.133769  0.155928  \n",
       "3  0.098842  0.103589  0.090239  0.109755  0.036189  0.149799  0.063875  \n",
       "4  0.105096  0.068538  0.087177  0.117711  0.035451  0.092469  0.146810  \n",
       "\n",
       "[5 rows x 409 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/similarity.csv\", header = None)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74072299085794158"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=15)\n",
    "X_r = pca.fit(data).transform(data)\n",
    "\n",
    "variance_ratio = pca.explained_variance_ratio_\n",
    "sum(variance_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.511759</td>\n",
       "      <td>0.299994</td>\n",
       "      <td>-0.677522</td>\n",
       "      <td>0.004896</td>\n",
       "      <td>-0.187398</td>\n",
       "      <td>-0.371288</td>\n",
       "      <td>-0.032757</td>\n",
       "      <td>-0.040091</td>\n",
       "      <td>-0.029791</td>\n",
       "      <td>-0.042390</td>\n",
       "      <td>-0.192772</td>\n",
       "      <td>0.050916</td>\n",
       "      <td>-0.011074</td>\n",
       "      <td>0.165854</td>\n",
       "      <td>0.017355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.935505</td>\n",
       "      <td>-0.182531</td>\n",
       "      <td>-0.573641</td>\n",
       "      <td>0.065739</td>\n",
       "      <td>-0.059815</td>\n",
       "      <td>-0.031114</td>\n",
       "      <td>0.325290</td>\n",
       "      <td>-0.091466</td>\n",
       "      <td>0.280150</td>\n",
       "      <td>0.067097</td>\n",
       "      <td>0.067570</td>\n",
       "      <td>-0.050677</td>\n",
       "      <td>0.018321</td>\n",
       "      <td>-0.138163</td>\n",
       "      <td>0.049223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.059530</td>\n",
       "      <td>0.004480</td>\n",
       "      <td>-0.143592</td>\n",
       "      <td>-0.191153</td>\n",
       "      <td>-0.116708</td>\n",
       "      <td>-0.236284</td>\n",
       "      <td>-0.080479</td>\n",
       "      <td>-0.013179</td>\n",
       "      <td>-0.086101</td>\n",
       "      <td>-0.037904</td>\n",
       "      <td>0.074368</td>\n",
       "      <td>-0.037267</td>\n",
       "      <td>0.047775</td>\n",
       "      <td>-0.032541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.060781</td>\n",
       "      <td>-0.376285</td>\n",
       "      <td>-0.108082</td>\n",
       "      <td>-0.083886</td>\n",
       "      <td>-0.137554</td>\n",
       "      <td>0.192783</td>\n",
       "      <td>0.125893</td>\n",
       "      <td>-0.062755</td>\n",
       "      <td>-0.111162</td>\n",
       "      <td>0.176417</td>\n",
       "      <td>-0.318316</td>\n",
       "      <td>-0.227665</td>\n",
       "      <td>-0.047157</td>\n",
       "      <td>0.022139</td>\n",
       "      <td>-0.071486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.836552</td>\n",
       "      <td>-0.149040</td>\n",
       "      <td>-0.021487</td>\n",
       "      <td>0.184041</td>\n",
       "      <td>-0.121461</td>\n",
       "      <td>-0.059982</td>\n",
       "      <td>-0.313901</td>\n",
       "      <td>-0.023993</td>\n",
       "      <td>0.035755</td>\n",
       "      <td>-0.031600</td>\n",
       "      <td>-0.078603</td>\n",
       "      <td>0.111622</td>\n",
       "      <td>-0.023264</td>\n",
       "      <td>0.136501</td>\n",
       "      <td>-0.083630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.511759  0.299994 -0.677522  0.004896 -0.187398 -0.371288 -0.032757   \n",
       "1  0.935505 -0.182531 -0.573641  0.065739 -0.059815 -0.031114  0.325290   \n",
       "2  0.000967  0.059530  0.004480 -0.143592 -0.191153 -0.116708 -0.236284   \n",
       "3  1.060781 -0.376285 -0.108082 -0.083886 -0.137554  0.192783  0.125893   \n",
       "4  0.836552 -0.149040 -0.021487  0.184041 -0.121461 -0.059982 -0.313901   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0 -0.040091 -0.029791 -0.042390 -0.192772  0.050916 -0.011074  0.165854   \n",
       "1 -0.091466  0.280150  0.067097  0.067570 -0.050677  0.018321 -0.138163   \n",
       "2 -0.080479 -0.013179 -0.086101 -0.037904  0.074368 -0.037267  0.047775   \n",
       "3 -0.062755 -0.111162  0.176417 -0.318316 -0.227665 -0.047157  0.022139   \n",
       "4 -0.023993  0.035755 -0.031600 -0.078603  0.111622 -0.023264  0.136501   \n",
       "\n",
       "         14  \n",
       "0  0.017355  \n",
       "1  0.049223  \n",
       "2 -0.032541  \n",
       "3 -0.071486  \n",
       "4 -0.083630  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_data = pd.DataFrame(data = X_r)\n",
    "pca_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.32653609764500841, 0.31114649635496533),\n",
       " (3, 0.26878708644583676, 0.25302553239582543),\n",
       " (4, 0.22822941490644358, 0.199747708057993),\n",
       " (5, 0.21432472156233803, 0.16854871282084341),\n",
       " (6, 0.21908894460323547, 0.15629491659364617),\n",
       " (7, 0.19807339380439576, 0.16026130652866294),\n",
       " (8, 0.18818627055090537, 0.16257283771661485),\n",
       " (9, 0.20630360304784484, 0.17166093545934455),\n",
       " (10, 0.1834799509250124, 0.17186383613525752),\n",
       " (11, 0.18582045380829421, 0.17157599103587767),\n",
       " (12, 0.18150895922034202, 0.15752581646451264),\n",
       " (13, 0.18120283164922402, 0.15887806252250178),\n",
       " (14, 0.17606274571469413, 0.15579444073746188),\n",
       " (15, 0.17762717246209489, 0.14595241439395493),\n",
       " (16, 0.1645861021088291, 0.14650493533946163),\n",
       " (17, 0.1693588736327237, 0.15175131396683375),\n",
       " (18, 0.17718344626461896, 0.15103310209565457),\n",
       " (19, 0.16499282711399668, 0.15485628708061208)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [] #(n clusters, sillouette score)\n",
    "data_in = pca_data\n",
    "for i in range(2,20):\n",
    "    estimator1 = KMeans(init='k-means++', n_clusters=i, n_init=10)\n",
    "    pred1 = estimator1.fit_predict(data_in)\n",
    "    score1 = metrics.silhouette_score(data_in, pred1,\n",
    "                                      metric='euclidean',\n",
    "                                      sample_size=None)\n",
    "    estimator2 = AgglomerativeClustering(n_clusters=i)\n",
    "    pred2 = estimator2.fit_predict(data_in)\n",
    "    score2 = metrics.silhouette_score(data_in, pred2,\n",
    "                                      metric='euclidean',\n",
    "                                      sample_size=None)\n",
    "    results.append((i,score1, score2))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Interpretation of Sillhouette Scores:\n",
    "#\n",
    "# 0.71-1.0\n",
    "# A strong structure has been found\n",
    "\n",
    "# 0.51-0.70\n",
    "# A reasonable structure has been found\n",
    "\n",
    "# 0.26-0.50\n",
    "# The structure is weak and could be artificial. Try additional methods of data analysis.\n",
    "\n",
    "# < 0.25\n",
    "# No substantial structure has been found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=167281, minmax=(0.0, 1.0), mean=0.13723387175965843, variance=0.0091283430177550636, skewness=2.392798093365969, kurtosis=15.588262472547648)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalist = data.values.flatten()\n",
    "stats.describe(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# skewness 2.3 - very right skewed\n",
    "# kurtosis 15 - very heavy tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>399</th>\n",
       "      <th>400</th>\n",
       "      <th>401</th>\n",
       "      <th>402</th>\n",
       "      <th>403</th>\n",
       "      <th>404</th>\n",
       "      <th>405</th>\n",
       "      <th>406</th>\n",
       "      <th>407</th>\n",
       "      <th>408</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>409.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>409.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.157265</td>\n",
       "      <td>0.094926</td>\n",
       "      <td>0.134529</td>\n",
       "      <td>0.090133</td>\n",
       "      <td>0.099970</td>\n",
       "      <td>0.125356</td>\n",
       "      <td>0.194999</td>\n",
       "      <td>0.106992</td>\n",
       "      <td>0.127233</td>\n",
       "      <td>0.193083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083229</td>\n",
       "      <td>0.153429</td>\n",
       "      <td>0.122245</td>\n",
       "      <td>0.170902</td>\n",
       "      <td>0.111994</td>\n",
       "      <td>0.148686</td>\n",
       "      <td>0.154845</td>\n",
       "      <td>0.051516</td>\n",
       "      <td>0.189054</td>\n",
       "      <td>0.163488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.090132</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>0.074346</td>\n",
       "      <td>0.057276</td>\n",
       "      <td>0.061843</td>\n",
       "      <td>0.071652</td>\n",
       "      <td>0.094538</td>\n",
       "      <td>0.079308</td>\n",
       "      <td>0.076852</td>\n",
       "      <td>0.092241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064047</td>\n",
       "      <td>0.087292</td>\n",
       "      <td>0.071236</td>\n",
       "      <td>0.090355</td>\n",
       "      <td>0.076037</td>\n",
       "      <td>0.080993</td>\n",
       "      <td>0.088176</td>\n",
       "      <td>0.057331</td>\n",
       "      <td>0.104368</td>\n",
       "      <td>0.084692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.095475</td>\n",
       "      <td>0.059986</td>\n",
       "      <td>0.091369</td>\n",
       "      <td>0.063438</td>\n",
       "      <td>0.067523</td>\n",
       "      <td>0.081794</td>\n",
       "      <td>0.138117</td>\n",
       "      <td>0.062774</td>\n",
       "      <td>0.074797</td>\n",
       "      <td>0.132706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049780</td>\n",
       "      <td>0.099012</td>\n",
       "      <td>0.082079</td>\n",
       "      <td>0.107230</td>\n",
       "      <td>0.066490</td>\n",
       "      <td>0.097228</td>\n",
       "      <td>0.095041</td>\n",
       "      <td>0.026588</td>\n",
       "      <td>0.122545</td>\n",
       "      <td>0.106510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.147086</td>\n",
       "      <td>0.088674</td>\n",
       "      <td>0.128465</td>\n",
       "      <td>0.090359</td>\n",
       "      <td>0.092598</td>\n",
       "      <td>0.116095</td>\n",
       "      <td>0.195566</td>\n",
       "      <td>0.088939</td>\n",
       "      <td>0.116063</td>\n",
       "      <td>0.197014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067753</td>\n",
       "      <td>0.141425</td>\n",
       "      <td>0.109932</td>\n",
       "      <td>0.163609</td>\n",
       "      <td>0.101180</td>\n",
       "      <td>0.138681</td>\n",
       "      <td>0.141362</td>\n",
       "      <td>0.040990</td>\n",
       "      <td>0.168469</td>\n",
       "      <td>0.161103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.206936</td>\n",
       "      <td>0.125586</td>\n",
       "      <td>0.174177</td>\n",
       "      <td>0.109766</td>\n",
       "      <td>0.123822</td>\n",
       "      <td>0.155673</td>\n",
       "      <td>0.245922</td>\n",
       "      <td>0.137885</td>\n",
       "      <td>0.176197</td>\n",
       "      <td>0.242717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105903</td>\n",
       "      <td>0.197754</td>\n",
       "      <td>0.157854</td>\n",
       "      <td>0.229869</td>\n",
       "      <td>0.138175</td>\n",
       "      <td>0.200097</td>\n",
       "      <td>0.211008</td>\n",
       "      <td>0.065362</td>\n",
       "      <td>0.250747</td>\n",
       "      <td>0.216112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 409 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1           2           3           4           5    \\\n",
       "count  409.000000  409.000000  409.000000  409.000000  409.000000  409.000000   \n",
       "mean     0.157265    0.094926    0.134529    0.090133    0.099970    0.125356   \n",
       "std      0.090132    0.064100    0.074346    0.057276    0.061843    0.071652   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.095475    0.059986    0.091369    0.063438    0.067523    0.081794   \n",
       "50%      0.147086    0.088674    0.128465    0.090359    0.092598    0.116095   \n",
       "75%      0.206936    0.125586    0.174177    0.109766    0.123822    0.155673   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "              6           7           8           9       ...             399  \\\n",
       "count  409.000000  409.000000  409.000000  409.000000     ...      409.000000   \n",
       "mean     0.194999    0.106992    0.127233    0.193083     ...        0.083229   \n",
       "std      0.094538    0.079308    0.076852    0.092241     ...        0.064047   \n",
       "min      0.000000    0.000000    0.000000    0.000000     ...        0.000000   \n",
       "25%      0.138117    0.062774    0.074797    0.132706     ...        0.049780   \n",
       "50%      0.195566    0.088939    0.116063    0.197014     ...        0.067753   \n",
       "75%      0.245922    0.137885    0.176197    0.242717     ...        0.105903   \n",
       "max      1.000000    1.000000    1.000000    1.000000     ...        1.000000   \n",
       "\n",
       "              400         401         402         403         404         405  \\\n",
       "count  409.000000  409.000000  409.000000  409.000000  409.000000  409.000000   \n",
       "mean     0.153429    0.122245    0.170902    0.111994    0.148686    0.154845   \n",
       "std      0.087292    0.071236    0.090355    0.076037    0.080993    0.088176   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.099012    0.082079    0.107230    0.066490    0.097228    0.095041   \n",
       "50%      0.141425    0.109932    0.163609    0.101180    0.138681    0.141362   \n",
       "75%      0.197754    0.157854    0.229869    0.138175    0.200097    0.211008   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "              406         407         408  \n",
       "count  409.000000  409.000000  409.000000  \n",
       "mean     0.051516    0.189054    0.163488  \n",
       "std      0.057331    0.104368    0.084692  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.026588    0.122545    0.106510  \n",
       "50%      0.040990    0.168469    0.161103  \n",
       "75%      0.065362    0.250747    0.216112  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 409 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Agglomerative Clustering has similar performance to Kmeans w.r.t. sillhouette score\n",
    "# PCA is not effective at dimension reduction, 10 features -> 71% variance, 15 features -> 75% variance\n",
    "# Sillhouette score goes up with fewer features and clusters, but still quite low (10 features, 2 clusters -> ~32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAJCkQhkAklQoA0CSCvX/AepWLegF8l/HAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x104273208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p, x = np.histogram(datalist, bins=len(datalist)//10 ) \n",
    "x = x[:-1] + (x[1] - x[0])/2   \n",
    "f = UnivariateSpline(x, p, s=len(datalist)//10 )\n",
    "plt.plot(x, f(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-225144.99785440462,\n",
       "  -109390.00721542485,\n",
       "  -462679.40904086945,\n",
       "  -417307.10461620212],\n",
       " [59845.480843859492,\n",
       "  -109851.78219306766,\n",
       "  -495970.15281058411,\n",
       "  -436335.03741295607],\n",
       " [446513.41493546637,\n",
       "  -110057.24758096627,\n",
       "  -527465.92825596838,\n",
       "  -448035.69477576774],\n",
       " [899237.86860036431,\n",
       "  -109807.88668806414,\n",
       "  -546143.45740111475,\n",
       "  -453211.92807501514],\n",
       " [1334097.1907499526,\n",
       "  -110621.80289022374,\n",
       "  -550328.48959018243,\n",
       "  -458194.96953782858],\n",
       " [1808887.8590497391,\n",
       "  -111114.84193643444,\n",
       "  -569993.66925302951,\n",
       "  -462787.63510559505],\n",
       " [2295760.639076286,\n",
       "  -112119.04783880879,\n",
       "  -574684.66010901635,\n",
       "  -465274.69033799745],\n",
       " [2773600.5319288685,\n",
       "  -113430.4623268859,\n",
       "  -589127.03904797882,\n",
       "  -464600.5811360419],\n",
       " [3260288.1513366164,\n",
       "  -113074.12014443416,\n",
       "  -593073.9477102455,\n",
       "  -464169.48706244782],\n",
       " [3762663.1489825249,\n",
       "  -114281.75787657057,\n",
       "  -601140.959626553,\n",
       "  -466987.91314720304],\n",
       " [4242870.6562151425,\n",
       "  -114603.79345124436,\n",
       "  -596957.19003294222,\n",
       "  -466637.71852786583],\n",
       " [4743510.8402114594,\n",
       "  -115073.09061206947,\n",
       "  -612618.01714626397,\n",
       "  -463162.52037133335],\n",
       " [5237301.8629751438,\n",
       "  -115966.54599418014,\n",
       "  -611022.90291990165,\n",
       "  -464544.39136656898],\n",
       " [5735767.4527128041,\n",
       "  -116889.21203530219,\n",
       "  -608835.47231090639,\n",
       "  -465379.67498162214]]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GMM\n",
    "bic_scores = [] # lower is better\n",
    "for i in range(2,16): # components\n",
    "    score_i = []\n",
    "    cov_types = [\"full\",\"tied\",\"diag\",\"spherical\"]\n",
    "    for j in range(4):\n",
    "        estimator = GaussianMixture(n_components = i, covariance_type = cov_types[j])\n",
    "        estimator.fit(data)\n",
    "        pred = estimator.predict(data)\n",
    "        # score = estimator.score(data)\n",
    "        score = estimator.bic(data)\n",
    "        score_i.append(score)\n",
    "    bic_scores.append(score_i)\n",
    "bic_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# About the GMM\n",
    "# Pros\n",
    "# Speed:\tIt is the fastest algorithm for learning mixture models\n",
    "# Agnostic:\tAs this algorithm maximizes only the likelihood, it will not bias the means towards zero, or bias the cluster sizes to have specific structures that might or might not apply.\n",
    "# Cons\n",
    "# Singularities:\tWhen one has insufficiently many points per mixture, estimating the covariance matrices becomes difficult, and the algorithm is known to diverge and find solutions with infinite likelihood unless one regularizes the covariances artificially.\n",
    "# Number of components:\n",
    "#  \tThis algorithm will always use all the components it has access to, needing held-out data or information theoretical criteria to decide how many components to use in the absence of external cues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results2 = []\n",
    "# data_in = pca_data\n",
    "# #computes mean similarity score within the set\n",
    "# def set_mean(s):\n",
    "#     sm = 0\n",
    "#     ct = 0\n",
    "#     for i in s:\n",
    "#         for j in range(409):\n",
    "#             if j in s:\n",
    "#                 ct += 1\n",
    "#                 sm += data.iat[i,j]\n",
    "#     return sm/ct\n",
    "\n",
    "# #computes set_mean score for all sets, i = number of clusters\n",
    "# def gen_score(labels,i):\n",
    "#     sets = [set()]*i\n",
    "#     for j in range(len(labels)):\n",
    "#         sets[labels[j]].add(j)\n",
    "#     scores = [set_mean(x) for x in sets]\n",
    "#     return scores\n",
    "            \n",
    "# # new scoring metric\n",
    "# for i in range(2,3):\n",
    "#     estimator1 = KMeans(init='k-means++', n_clusters=i, n_init=10)\n",
    "#     pred1 = estimator1.fit_predict(data_in)\n",
    "#     score1 = gen_score(pred1,i)\n",
    "    \n",
    "#     estimator2 = AgglomerativeClustering(n_clusters=i)\n",
    "#     pred2 = estimator2.fit_predict(data_in)\n",
    "#     score2 = gen_score(pred2,i)\n",
    "#     results2.append((i,score1, score2))\n",
    "# results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the above doesn't work, silly me."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
